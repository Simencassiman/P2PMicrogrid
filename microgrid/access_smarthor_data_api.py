# Python Librariesimport jsonfrom typing import Dict, List, Anyimport urllibimport osimport numpy as npimport requestsfrom datetime import datetimefrom datetime import timedeltaimport matplotlib.pyplot as pltimport pandas as pd# Local modulesfrom microgrid import KWH_TO_WS, SECONDS_PER_MINUTE, MINUTES_PER_HOURfrom config import user, pswd, TIME_SLOT, DATA_PATH# Format access pointURL = 'https://st-dev-data-api.azurewebsites.net'DATE_FORMAT_STR = "%Y-%m-%d"# url = urllib.parse.urljoin(URL, '/api/v0.1/buildings/energyville1/transfo/realtime/properties')endpoints = {    'load': {'url': '/api/v0.1/buildings/energyville1/transfo/realtime',             'params': {'transfo_id': 'transfo1', 'properties': 'ActiveImport'}             },    'weather': {'url': '/api/v0.1/weather/forecasts/darksky/hourly/latest/',                'params':  {'locations': 'Genk'}                },    'pv': {'url': '/api/v0.1/buildings/energyville1/pv/roof/realtime/',           'params': {'properties': 'Ev1_PVRoofEactImport'}           }}# PV endpoint properties# [{"Property": "Ev1_PVRoofI1"}, {"Property": "Ev1_PVRoofI2"},# {"Property": "Ev1_PVRoofI3"}, {"Property": "Ev1_PVRoofV12"},# {"Property": "Ev1_PVRoofV23"}, {"Property": "Ev1_PVRoofV31"},# {"Property": "Ev1_PVRoofV1N"}, {"Property": "Ev1_PVRoofV2N"},# {"Property": "Ev1_PVRoofV3N"}, {"Property": "Ev1_PVRoofP1"},# {"Property": "Ev1_PVRoofP2"}, {"Property": "Ev1_PVRoofP3"},# {"Property": "Ev1_PVRoofPtot"}, {"Property": "Ev1_PVRoofQtot"},# {"Property": "Ev1_PVRoofStot"}, {"Property": "Ev1_PVRoofF"},# {"Property": "Ev1_PVRoofEactExport"}, {"Property": "Ev1_PVRoofEactImport"},# {"Property": "Ev1_PVRoofEactImportP1"}, {"Property": "Ev1_PVRoofEactImportP2"},# {"Property": "Ev1_PVRoofEactImportP3"}, {"Property": "Ev1_PVRoofEactImportPart"},# {"Property": "Ev1_PVRoofEreaExport"}, {"Property": "Ev1_PVRoofEreaImport"},# {"Property": "Ev1_PVRoofEreaImportPart"}, {"Property": "Ev1_PVRoofPpeak"},# {"Property": "Ev1_PVRoofQpeak"}, {"Property": "Ev1_PVRoofSpeak"}]}# Old code to store data# Weather# with open('../data/profiles_1.json') as file, open('../data/profiles_2.json', 'w') as out_file:#     d = json.load(file)#     json.dump(d | to_store, out_file)# PV# with open('../data/pv.json', 'w') as file:#     json.dump({'time': [t for i, t in enumerate(time) if i % 15 == 0],#                'pv': (pv / pv.max()).tolist()}, file)def reduce_time_to_slots(df: pd.DataFrame) -> pd.DataFrame:    df_new = pd.DataFrame(df['time'].iloc[::TIME_SLOT], columns=['time'])    df_new.sort_values(['time'], inplace=True)    # Format time    df_new[['date', 'time', 'utc']] = df_new['time'].str.extract(        r'(\d{4}-\d{2}-\d{2})\s(\d{2}:\d{2}:\d{2})(.\d{6}){0,1}([+-]\d{2}:\d{2})',        expand=True).iloc[:, [0, 1, 3]]    return df_newdef reduce_values_to_slots(df: pd.DataFrame, label: str) -> np.ndarray:    values = np.diff(df[label])    # load = np.array(df['load'])    extra_vals = (TIME_SLOT - (len(values) % TIME_SLOT)) if len(values) % TIME_SLOT != 0 else 0    values = (np.append(values,                      np.repeat(values[-1:], extra_vals)                      ) * KWH_TO_WS / SECONDS_PER_MINUTE            ).reshape((-1, TIME_SLOT)).mean(axis=1)    return valuesdef clean_time(df: pd.DataFrame) -> List[str]:    df[['hour', 'min', 'sec']] = df['time'].str.split(':', expand=True)    current_hour = -1    current_min = -1    time = []    nr_slots = MINUTES_PER_HOUR / TIME_SLOT    for _, row in df.iterrows():        date = datetime.fromisoformat(f'{row["date"]} {row["time"]}{row["utc"]}')        h, m = int(date.hour), round(int(date.minute) / TIME_SLOT)        if h == current_hour and m == current_min:            m += 1        elif h == current_hour and m - current_min > 1:            m -= 1        if m == nr_slots:            date = date.replace(minute=0) + timedelta(hours=1)        else:            date = date.replace(minute=m * TIME_SLOT)        time.append(f'{date.hour:02}:{date.minute:02}:00')        current_hour = date.hour        current_min = m % nr_slots    df.drop(columns=['hour', 'min', 'sec'], inplace=True)    return timedef load_energyville_data(result: requests.Response) -> pd.DataFrame:    # Extract data from response    df = pd.DataFrame([(reading['DateTimeMeasurement'], reading['ActiveImport']) for reading in result.json()['data']],                      columns=['time', 'load'])    # df = pd.DataFrame([(reading['DateTimeMeasurement'], reading['ActiveImport']) for reading in result],    #                   columns=['time', 'load'])    df.sort_values(['time'], inplace=True)    df.fillna(method='ffill', inplace=True)     # Fill None (NaN) values with first previous valid value    # Format time    df_new = reduce_time_to_slots(df)    df_new['time'] = clean_time(df_new)    # Format load    df_new['load'] = np.abs(reduce_values_to_slots(df, 'load'))    return df_newdef weather_data(result: requests.Response) -> pd.DataFrame:    # Extract data from response    time: List[datetime]    time, *series = \        zip(*[(datetime.fromisoformat(reading['DateTimeMeasurement']), reading['Temperature'], reading['CloudCover'], reading['Humidity'])              for reading in result.json()['data']])    # time, *series = \    #     zip(*[(datetime.fromisoformat(reading['DateTimeMeasurement']), reading['Temperature'], reading['CloudCover'],    #            reading['Humidity'])    #           for reading in result])    # Interpolate dates    dates = [ti.isoformat() for d in time for ti in [d.replace(minute=ts * TIME_SLOT)                                                     for ts in range(int(MINUTES_PER_HOUR / TIME_SLOT))]]    tt = np.arange(len(dates))    t = tt[::4]    df = pd.DataFrame(dates, columns=['time'])    df.sort_values(['time'], inplace=True)    df[['date', 'time', 'utc']] = df['time']\        .str.extract(r'(\d{4}-\d{2}-\d{2})T(\d{2}:\d{2}:\d{2})([+-]\d{2}:\d{2})',                     expand=True)    # Interpolate values    for label, data in zip(['temperature', 'cloud_cover', 'humidity'], series):        df[label] = np.interp(tt, t, data).tolist()    df.fillna(method='ffill', inplace=True)  # Fill None (NaN) values with first previous valid value    return dfdef pv_data(result: requests.Response) -> pd.DataFrame:    # Extract data from response    df = pd.DataFrame([(reading['DateTimeMeasurement'], reading['Value'])                       for reading in result.json()['data']], columns=['time', 'pv'])    # df = pd.DataFrame([(reading['DateTimeMeasurement'], reading['Value'])    #                    for reading in result], columns=['time', 'pv'])    df.sort_values(['time'], inplace=True)    df.fillna(method='ffill', inplace=True)    # Format time    df_new = reduce_time_to_slots(df)    df_new['time'] = clean_time(df_new)    # Format PV    df_new['pv'] = reduce_values_to_slots(df, 'pv')    return df_newdef handle_result(key: str, response: requests.Response) -> pd.DataFrame:    print('Handling response...')    # with open(os.path.join(data_path, f'latest_{key}.json'), 'w') as file:    #     json.dump(response.json()['data'], file)    if key == 'load':        return load_energyville_data(response)    elif key == 'weather':        return weather_data(response)    elif key == 'pv':        return pv_data(response)    return Nonedef get_endpoint_data(endpoint: str, params: Dict[str, Any]) -> pd.DataFrame:    print(f'Retrieving {endpoint}...')    url = urllib.parse.urljoin(URL, endpoints[endpoint]['url'])    # Send request    # with open(os.path.join(data_path, f'latest_{endpoint}.json')) as file:    #     response = json.load(file)    response = requests.get(url, params=params | endpoints[endpoint]['params'], auth=(user, pswd))    # Visualise / Save response    # print(result.text)    # return handle_result(endpoint, response)    if response.ok:        return handle_result(endpoint, response)    else:        print(f'{endpoint}: {response.status_code}')        return Nonedef get_all_endpoints(params: Dict[str, Any]) -> pd.DataFrame:    data: pd.DataFrame = None    for endpoint in endpoints.keys():        if data is None:            data = get_endpoint_data(endpoint, params)        else:            if data is not None:                data = pd.merge(data, get_endpoint_data(endpoint, params), on=['date', 'time', 'utc'],                                how='outer', copy=False)    if data is not None:        data.fillna(method='ffill', inplace=True)    return datadef get_data(start: datetime, end: datetime, endpoint: str = None) -> pd.DataFrame:    dates = []    date = start    while date < end:        dates.append(date.isoformat())        date += timedelta(minutes=TIME_SLOT)    df = pd.DataFrame(dates, columns=['date'])    df[['date', 'time']] = df['date'].str.extract(r'(\d{4}-\d{2}-\d{2})T(\d{2}:\d{2}:\d{2})',                                                  expand=True)    params = {        # SmarThor parameters        'start': start.strftime(DATE_FORMAT_STR),        'end': end.strftime(DATE_FORMAT_STR),        'time_zone': 'Central European Standard Time'    }    if endpoint is None:        data = get_all_endpoints(params)    else:        data = get_endpoint_data(endpoint, params)    if data is not None:        df = pd.merge(df, data, on=['date', 'time'], how='left', copy=True)    df.fillna(method='ffill', inplace=True)    df.fillna(method='bfill', inplace=True)    df = df[-df[['date', 'time', 'utc']].duplicated()]    return df#### Run ####if __name__ == "__main__":    start = datetime(2021, 5, 1)    end = datetime(2021, 12, 1)    key = 'pv'    # Send request    d = get_data(start, end)    print(d.head())    print(len(d))    # Visualise / Save response    # for k, v in d.items():    #     print(k)    #     print(v)    # plt.plot(d['date'] + ' ' + d['time'] + d['utc'], d['load'])    # plt.show()